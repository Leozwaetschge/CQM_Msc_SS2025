{"cells":[{"cell_type":"markdown","metadata":{"id":"7NVh9Kh_2g_G"},"source":["***Installing Packages Needed for This Notebook and/or Beyond***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbEtiulx2g_R"},"outputs":[],"source":["#%pip install tensorflow\n","#%pip install --upgrade pip\n","#%pip install numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAQTwjfV2g_Y"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"tyYvv78a2g_e"},"source":["***Fast standard tensors definition***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-MoewYW2g_e"},"outputs":[],"source":["identity_4x4 = np.eye(4)  # takes only one dimension (square matrix)\n","identity_4x4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUrxPtwF2g_f"},"outputs":[],"source":["zero_vector_4 = np.zeros(4)\n","zero_vector_4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-spJlnOM2g_f"},"outputs":[],"source":["zero_matrix_4x4 = np.zeros((4, 4))\n","zero_matrix_4x4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IU7vBoLW2g_l"},"outputs":[],"source":["ones_matrix_4x4 = np.ones((4, 4))\n","ones_matrix_4x4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Z_U8znT2g_l"},"outputs":[],"source":["progression_vector = np.arange(10)\n","progression_vector"]},{"cell_type":"markdown","metadata":{"id":"PcbXZomF2g_m"},"source":["***Linear algebra operations***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuAq38pI2g_r"},"outputs":[],"source":["a = np.random.uniform(-1, 1, size = 5) + 1.0j * np.random.uniform(-1, 1, size = 5)\n","    # define a random complex vector from U[-1, 1] with size 5\n","#print(\"a =\",a)\n","\n","b = np.random.normal(loc = 0, scale = 1, size = 5) + 1.0j * np.random.normal(loc = 0, scale = 1, size = 5)\n","    # define a random complex vector from N(0, 1) (normal distribution of mean 0 and std 1) with size 5\n","#print(\"b =\",b)\n","\n","M = np.random.uniform(-1, 1, size = (5, 5)) + 1.0j * np.random.uniform(-1, 1, size = (5, 5))\n","    # random complex matrix from U[-1, 1] with dimensions 5x5\n","#print(\"M =\",M)\n","\n","N = np.random.normal(-1, 1, size = (5, 5)) + 1.0j * np.random.normal(-1, 1, size = (5, 5))\n","    # random complex matrix from N[-1, 1] with dimensions 5x5\n","#print(\"N =\",N)\n","\n","M = M + M.conj().T  # make it Hermitian (all the good matrices are Hermitian, aren't they?)\n","N = N + N.conj().T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-WTt2Z32g_y"},"outputs":[],"source":["print(a + b)  # point-wise vector addition\n","print(a - b)  # point-wise vector subtraction\n","print(a * b)  # point-wise vector multiplication\n","print(a / b)  # point-wise vector division (be careful here!)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QC8plYNw2g_y"},"outputs":[],"source":["# scalar products\n","print(np.dot(a.conj().T, a))  # |a|^2 = (a^*, a)\n","print(np.dot(a.conj().T, b))  # (a^*, b)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHJf7SbZ2hAP"},"outputs":[],"source":["# scalar products\n","print(np.dot(a.conj().T, a))  # |a|^2 = (a^*, a)\n","print(np.dot(a.conj().T, b))  # (a^*, b)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fR1IqAZV2hAq"},"outputs":[],"source":["# matrix operations\n","M + N  # point-wise matrix addition\n","M - N  # point-wise matrix subtraction\n","M * N  # point-wise matrix multiplication\n","M / N  # point-wise matrix division"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgpayIo52hAq"},"outputs":[],"source":["# matrix-vector operations\n","a.dot(M)  # a.M standard vector-matrix multiplication\n","np.dot(a, M)  # the same thing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxEXrZCB2hAr"},"outputs":[],"source":["# matrix-matrix operations\n","np.dot(M, N)  # M.N matrix multiplication, although np.matmul is more often used for matrix multiplication than np.dot, as is np.einsum (see below)\n","M.dot(N)  # the same thing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xi3Ay1VI2hAw"},"outputs":[],"source":["np.trace(M)  # trace M\n","np.trace(M.dot(N))  # trace MN"]},{"cell_type":"markdown","metadata":{"id":"c-CnbYSl2hAx"},"source":["Einstein summation notation and ***np.einsum*** (a **very** useful operation)\n","\n","Supposing one has two tensors with arbitrarily many indexes (vector, matrix, 3--tensor, ...) $M_{i_1, i_2, \\ldots, i_n}$ and $N_{j_1, j_2, \\ldots, j_m}$ and writes an expression in the form $\\sum\\limits_{k_1, k_2, \\ldots k_l} M_{i_1, i_2, \\ldots, i_n} N_{j_1, j_2, \\ldots, j_m}.$\n","\n","For instance: $$|a|^2 = \\sum_i a^{\\dagger}_i a_i,\\;\\text{vector norm},$$\n","$$b_j = (M a)_j = \\sum_k M_{jk} a_k,\\;\\text{matrix-vector multiplication}$$\n","$$(MN)_{ij} = \\sum_k M_{ik} B_{kj},\\;\\text{matrix-matrix multiplication}$$\n","$$(a \\otimes b)_{ij} =  a_i b_j,\\;\\text{outer product}.$$\n","\n","\n","**Einstein summation notation**: any repeated index implies summation over this index: $$|a|^2 = a^{\\dagger}_i a_i,$$, $$b_j = (M a)_j = A_{jk} a_k,$$, $$(MN)_{ij} = M_{ik} B_{kj},$$, $$(a \\otimes b)_{ij} =  a_i b_j.$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TV6Am_4Z2hAx"},"outputs":[],"source":["#  now several examples of tensor contraction using np.einsum:\n","\n","np.einsum('i,i->', a.conj(), a)  # |a|^2\n","np.einsum('i,i->', b.conj(), a)  # b^dag a\n","np.einsum('ik,kj->ij', M, N)  # M.N matrix-matrix\n","np.einsum('ik,k->i', M, a)  # M.a matrix-vector\n","np.einsum('i,j->ij', a, b)  # outer product\n","np.einsum('ii->', M)  # trace M\n","np.einsum('ij,ji->', M, N)  # trace MN\n","np.einsum('i,ij,j->ij', a, M, b)  # M_ij -> M_ij a_i b_j)\n","\n","# np.einsum is sometimes the fastest way to perform an operation. For instance,\n","# np.einsum('ij,ji->', M, M) (trace MN) runs in O(N^2) operations, while np.trace(M.dot(N)) in O(N^3) operations\n","\n","# np.einsum is a Swiss army knife: inside it chooses the fastest numpy implementation for contraction itself"]},{"cell_type":"markdown","metadata":{"id":"_i1DsyK02hBR"},"source":["**Fast slicing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BqUO3HFV2hBS"},"outputs":[],"source":["#  split vector into odd and even index parts:\n","a = np.arange(10)\n","even_indexes = np.arange(0, a.shape[0], 2)\n","odd_indexes = np.arange(1, a.shape[0], 2)\n","\n","print(a, a[even_indexes], a[odd_indexes])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQzXHWdA2hBS"},"outputs":[],"source":["# take the first and the third row of the matrix\n","M[np.array([0, 2]), :]  # this is a new matrix of shape (2,5) containing the first and third rows only of the matrix M"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxjQBvqX2hBT"},"outputs":[],"source":["#  how about more complex tensors?\n","A = np.random.uniform(-1, 1, size = (4, 4, 4, 4))  # 4x4x4x4 tensor\n","print(A.shape)\n","#  take only 1-st and 3-rd indexes in the first index:\n","B = A[np.array([0, 2]), ...]  # \"...\" means \"full slice in all other dimensions\"\n","print(B.shape)\n","#  take the last index in the 2-nd dimension:\n","C = A[:, -1, :, :]\n","print(C.shape)  # the dimensionality reduced\n","\n","C = A[:, -1:, :, :]  # if want to keep the degenerate dimension\n","print(C.shape)\n","\n","#  or\n","C = A[:, -1, :, :][:, np.newaxis, :, :]  # remove then restore the dimension\n","print(C.shape)"]},{"cell_type":"markdown","metadata":{"id":"wVEzAo6e2hBY"},"source":["Final: **solvers and advanced linear algebra**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjpJFnQZ2hBZ"},"outputs":[],"source":["eigvals, U = np.linalg.eigh(M)  # diagonalise Hermitian conjugate matrix\n","print(eigvals.shape, U.shape)\n","#  U[:, i] contains the i-th eigenvector corresponding to the eigenvalue i (eigvals[i])\n","\n","#  check that M v_i = lambda_i v_i for all i\n","[np.allclose(U[:, i] * eigvals[i], M.dot(U[:, i])) for i in range(eigvals.shape[0])]\n","#  actually (eigentlich) eigenvectors!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcO-4ZzL2hBZ"},"outputs":[],"source":["#  also, the following must hold: U.D.U^{dag} = M\n","np.allclose(U.dot(np.diag(eigvals)).dot(U.conj().T), M)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ByPk3Ra2hBf"},"outputs":[],"source":["#  SVD decomposition (required for DQMC)\n","U, s, V = np.linalg.svd(M, full_matrices = True)\n","np.allclose(U.dot(np.diag(s)).dot(V), M)\n","\n","# and may other! LU, QR, et cetera"]},{"cell_type":"markdown","metadata":{"id":"yjKGA1D_2hBf"},"source":["Bonus: **for-loops vs numpy** comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yT5geBSq2hBg"},"outputs":[],"source":["a = np.arange(100)\n","b = np.arange(100)\n","%timeit [a[i] * b[j] for i in range(100) for j in range(100)]\n","%timeit np.einsum('i,j->ij', a, b)  # numpy is ~240 times faster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDWjepoV2hBg"},"outputs":[],"source":["M = np.random.uniform(-1, 1, size = (100, 100))\n","N = np.random.uniform(-1, 1, size = (100, 100))\n","def prod_naive(M, N):\n","    C = np.zeros((100, 100))\n","    for i in range(100):\n","        for j in range(100):\n","            for k in range(100):\n","                C[i, j] += M[i, k] * N[k, j]\n","    return C\n","%timeit prod_naive(M, N)\n","%timeit M.dot(N)  # numpy is ~ 60 times faster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N707skoo2hBm"},"outputs":[],"source":["def prod_naive(M, a):\n","    b = np.zeros(100)\n","    for j in range(100):\n","        for k in range(100):\n","            b[j] += M[j, k] * a[k]\n","    return b\n","%timeit prod_naive(M, a)\n","%timeit M.dot(a)  # numpy is ~ 60 times faster"]},{"cell_type":"markdown","metadata":{"id":"-f33gdp72hBm"},"source":["Take home message: **always avoid using pythonic for-loops**, they are **very slow**. You are **very unlikely** to meet any linear algebra operation that can not be done purely within numpy."]},{"cell_type":"markdown","metadata":{"id":"iuaLKJAf2hBn"},"source":["**Excercises**: using only numpy routines (for objects creation and manipulation), compute the following: $$\\sum\\limits_{i=0}^{10} i,\\; \\sum\\limits_{i = 0}^{10} 2^i,\\;\\sum\\limits_{i = 0}^{10} i 2^i,$$\n","\n","$$\\sum\\limits_{n=0}^{9} e^{2 \\pi i n / 10},\\;\\sum\\limits_{n=0}^{9} e^{2 \\pi i n / 10} n,$$\n","\n","$$a^{\\dagger} M a, a = (0, 1, \\ldots, 10), M_{ij} = ij.$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NS8XqMZK2hBn"},"outputs":[],"source":["# WRITE SOLUTIONS HERE\n","\n","# Sum 1\n","sum_1 = np.sum(np.arange(11))\n","print(\"sum_1 (not einsum) = \",sum_1)\n","# Could also use np.einsum, though for very simple operations like these, the time saved is not significant, so np.sum is just fine.\n","sum_1 = np.einsum('i->',np.arange(11)) #\n","print(\"sum_1 (einsum) = \",sum_1)\n","print()\n","\n","# Sum 2\n","sum_2 = np.sum(2**np.arange(11))\n","print(\"sum_2 (not einsum) = \",sum_2)\n","# einsum (same answer produced, and once again, for simple operations like this, einsum is not needed, np.sum is just fine)\n","sum_2 = np.einsum('i->',2**np.arange(11))\n","print(\"sum_2 (einsum) = \",sum_2)\n","print()\n","\n","# Sum 3\n","sum_3 = np.sum(np.arange(11) * (2**np.arange(11)))\n","print(\"sum_3 (not einsum) = \",sum_3)\n","# einsum\n","sum_3 = np.einsum('i,i->',np.arange(11),2**np.arange(11))\n","print(\"sum_3 (einsum) =\",sum_3)\n","print()\n","\n","# Sum 4\n","sum_4 = np.sum(np.exp(1j*2*np.pi/10)**np.arange(10))\n","print(\"sum_4 (not einsum) = \",sum_4)\n","# einsum\n","sum_4 = np.einsum('i->',np.exp(1j*2*np.pi/10)**np.arange(10))\n","print(\"sum_4 (einsum) =\",sum_4)\n","print()\n","# Note sum_4 is actually zero, which you can show using geometric series.\n","# Also, if the result of the np.einsum operation for sum_4 \"looks different\"\n","# than the result of the np.sum operation, it's just a question of precision-\n","# if you look carefully, both results are actually 0.\n","\n","# Sum 5\n","sum_5 = np.sum(np.exp(1j*2*np.pi/10)**np.arange(10) * np.arange(10))\n","print(\"sum_5 (not einsum) = \",sum_5)\n","# einsum\n","sum_5 = np.einsum('i,i->',np.exp(1j*2*np.pi/10)**np.arange(10), np.arange(10))\n","print(\"sum_5 (einsum) = \",sum_5)\n","print()\n","\n","# Tensor product\n","print(\"aDag_M_a =\",np.einsum('i,ij,j->', a.conj(), M, a))"]},{"cell_type":"code","source":[],"metadata":{"id":"n5EBPLmDK_Gr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wHA9dswFlUQG"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}